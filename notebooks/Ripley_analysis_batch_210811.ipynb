{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ripley analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.8.2021 (8.9.2022) SÃ¶ren Doose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ripley analysis for a list of rois from different conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pickle\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy import stats\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import locan as lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc.show_versions(dependencies=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path(r'.') / '../data/Titration'\n",
    "assert directory.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = list(directory.glob('**/*.yaml'))\n",
    "print(f'Number of files: {len(files)}')\n",
    "for i, file in enumerate(files):\n",
    "    print(i,\":\", file);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computation(self, file, seed=None):\n",
    "    \"\"\"\n",
    "    Analysis procedure on a LocData object specified by file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    self : Pipeline\n",
    "        Pipeline object that collects results of the analysis procedure.\n",
    "    file : str\n",
    "        File path for roi-file.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Pipeline\n",
    "        The Pipeline object specified by `self`.\n",
    "    \"\"\"\n",
    "    # Prologue\n",
    "    self.file_indicator = Path(file) #.stem\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "        \n",
    "    # Load locdata\n",
    "    roi = lc.Roi.from_yaml(path=file)\n",
    "    roi.reference.file_path = str(Path(file)\n",
    "                              .relative_to(Path('.'))\n",
    "                              .with_name(Path(roi.reference.file_path).name)\n",
    "                             )\n",
    "    locdata = roi.locdata()\n",
    "    \n",
    "    # Select\n",
    "    condition = '0 < frame < 15_000 and 8000 < intensity' ##### PARAMETER #####\n",
    "    locdata = lc.select_by_condition(locdata, condition=condition)\n",
    "    locdata.reduce()\n",
    "    \n",
    "    # Prerequisites\n",
    "    if not len(locdata) > 100:\n",
    "        return None\n",
    "        \n",
    "    # Ripley\n",
    "    radii = np.linspace(1, 500, 100)  ##### PARAMETER #####\n",
    "    n_points = 200  ##### PARAMETER #####\n",
    "   \n",
    "    region = locdata.region\n",
    "\n",
    "    # experimental\n",
    "    subset = lc.random_subset(locdata, n_points=n_points, seed=rng)\n",
    "    self.rhf_estimates = lc.RipleysHFunction(radii=radii, region_measure=region.region_measure).compute(locdata, other_locdata=subset) \n",
    "    \n",
    "    # randomized\n",
    "    repetitions = 100  ##### PARAMETER #####\n",
    "        \n",
    "    self.rhf_randomized = []\n",
    "    for i in range(repetitions):\n",
    "        dat_randomized = lc.randomize(locdata, hull_region=region, seed=rng)\n",
    "        subset_random = lc.random_subset(dat_randomized, n_points=n_points, seed=rng)\n",
    "        self.rhf_randomized.append(lc.RipleysHFunction(radii=radii, region_measure=region.region_measure).compute(dat_randomized, other_locdata=subset_random))\n",
    "    \n",
    "    # Ripley control\n",
    "    n_localizations_per_dye = 11  ##### PARAMETER #####\n",
    "    min_localizations_per_dye = 1\n",
    "    n_dyes = round(len(locdata) / n_localizations_per_dye)\n",
    "    localization_precision = 12  ##### PARAMETER #####\n",
    "    \n",
    "    self.rhf_control = []\n",
    "    for i in range(repetitions):        \n",
    "        locdata_control = lc.simulate_dstorm(parent_intensity=n_dyes/region.region_measure, region=region, \n",
    "                                             cluster_mu=n_localizations_per_dye, min_points=min_localizations_per_dye, \n",
    "                                             cluster_std=localization_precision, seed=rng)\n",
    "        subset_control = lc.random_subset(locdata_control, n_points=n_points, seed=rng)\n",
    "        self.rhf_control.append(lc.RipleysHFunction(radii=radii, region_measure=region.region_measure).compute(locdata_control, other_locdata=subset_control))\n",
    "\n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.INFO)  # alternative logging.WARNING"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%time\n",
    "def worker(i, file, seed):\n",
    "    logger.info(f'Processing {i} : {file}')\n",
    "    try:\n",
    "        pipe = lc.Pipeline(computation=computation, file=file, seed=seed).compute()\n",
    "        logger.info(f'Computation completed for: {file}')\n",
    "        return pipe\n",
    "    except Exception as e:\n",
    "        logger.warning(f'Error in {file} : {e}')\n",
    "        return None\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "pipes = [worker(i, file, seed=rng) for i, file in tqdm(enumerate(files[0:2]), desc='Processed files:')]\n",
    "print(f'Number of pipes: {len(pipes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing with ray"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "ray.init()\n",
    "# ray.init(num_cpus = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "@ray.remote\n",
    "def worker(i, file, seed):\n",
    "    # Logging configuration needed for multiprocessing with ray\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    logger.info(f'Processing {i} : {file}')\n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "            pipe = lc.Pipeline(computation=computation, file=file, seed=seed).compute()\n",
    "        logger.info(f'Computation completed for: {file}') \n",
    "        return pipe    \n",
    "    except Exception as e:\n",
    "        logger.warning(f'Error in {file} : {e}')\n",
    "        return None\n",
    "    \n",
    "n_processes = len(files)\n",
    "ss = np.random.SeedSequence()\n",
    "child_seeds = ss.spawn(n_processes)\n",
    "\n",
    "futures = [worker.remote(i, file, seed) for i, (file, seed) in enumerate(zip(files, child_seeds))]\n",
    "pipes = ray.get(futures)\n",
    "print(f'Number of pipes: {len(pipes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[attr for attr in dir(pipes[0]) if not attr.startswith('__') and not attr.endswith('__')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save pickled pipes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pickle_directory = Path('.') / '../pickled_results'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i, pipe in enumerate(pipes):\n",
    "    file_path = pickle_directory / f'Ripley_pipelines_{i:03}.pickle'\n",
    "    pipe.computation = computation\n",
    "    pipe.parameter['computation'] = computation\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(pipe, file, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pickled pipes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pickle_files = list(pickle_directory.glob('Ripley_pipelines_*.pickle'))\n",
    "assert pickle_files"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pipes = []\n",
    "for file_path in pickle_files:\n",
    "    with open(file_path, 'rb') as file:\n",
    "        pipes.append(pickle.load(file))\n",
    "print(f'Number of pipes: {len(pipes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove None from pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of pipes: {len(pipes)}')\n",
    "pipes = [pipe for pipe in pipes if pipe]\n",
    "print(f'Number of pipes that are not None: {len(pipes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract from pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_scalars(pipelines):\n",
    "    \"\"\"\n",
    "    Collect scalar properties from Pipeline objects and assemble them in a pandas.DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pipelines : list(Pipeline)\n",
    "        Pipeline objects.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "    \"\"\"\n",
    "    dictionaries = []\n",
    "    for pipe in pipelines:\n",
    "\n",
    "        new_dict = {\n",
    "            'files': pipe.file_indicator\n",
    "            }\n",
    "\n",
    "        dictionaries.append(new_dict)\n",
    "        \n",
    "    return pd.DataFrame(dictionaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalars_df = collect_scalars(pipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce the file name to group identifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = ['*5ng*',\n",
    "           '*0-005*']\n",
    "\n",
    "choices_name =  ['dense',\n",
    "                 'sparse']\n",
    "   \n",
    "conditions = [[f.match(name) for f in scalars_df['files']] for name in choices]\n",
    "scalars_df['sample'] = np.select(conditions, choices_name, default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = scalars_df.groupby('sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(grouped.groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Grouped Ripley curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RipleysAnalysis_concat(cls, datasets):\n",
    "    if isinstance(datasets[0], cls):\n",
    "        dataframes = [analysis_class.results for analysis_class in datasets]\n",
    "    elif isinstance(datasets[0], (pd.DataFrame, pd.Series)):\n",
    "        dataframes = datasets\n",
    "    else:\n",
    "        raise TypeError\n",
    "    df = pd.concat(dataframes, axis=1, join=\"inner\")\n",
    "    new_analysis_class = cls()\n",
    "    new_analysis_class.results = df\n",
    "    return new_analysis_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RipleyAnalysis_statistics(self):\n",
    "    dataframe = self.results\n",
    "    self.statistics = pd.concat([\n",
    "        dataframe.mean(axis=1),\n",
    "        dataframe.std(axis=1),\n",
    "        dataframe.sem(axis=1),\n",
    "        dataframe.quantile(0.05, axis=1),\n",
    "        dataframe.quantile(0.95, axis=1)],\n",
    "        axis=1)\n",
    "    self.statistics.rename(columns={0:'mean', 1:'std', 2:'sem', 0.05:'CI_lower', 0.95:'CI_upper'}, inplace=True)\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_rhf_estimates = {}\n",
    "grouped_rhf_randomized = {}\n",
    "grouped_rhf_control = {}\n",
    "\n",
    "for name, group in grouped:\n",
    "    # experimental\n",
    "    rhf_estimates = [pipes[i].rhf_estimates for i in group.index]\n",
    "    rhf_estimates = RipleysAnalysis_concat(cls=lc.RipleysHFunction, datasets=rhf_estimates)\n",
    "    rhf_estimates = RipleyAnalysis_statistics(rhf_estimates)\n",
    "    grouped_rhf_estimates[name] = rhf_estimates\n",
    "    \n",
    "    # randomized\n",
    "    rhf_randomized = []\n",
    "    for n in range(len(pipes[0].rhf_randomized)):\n",
    "        rhf_randomized_ = [pipes[i].rhf_randomized[n] for i in group.index]\n",
    "        rhf_randomized_ = RipleysAnalysis_concat(cls=lc.RipleysHFunction, datasets=rhf_randomized_)\n",
    "        rhf_randomized_ = RipleyAnalysis_statistics(rhf_randomized_)\n",
    "        rhf_randomized.append(rhf_randomized_.statistics['mean'])\n",
    "    \n",
    "    rhf_randomized = RipleysAnalysis_concat(cls=lc.RipleysHFunction, datasets=rhf_randomized)\n",
    "    rhf_randomized = RipleyAnalysis_statistics(rhf_randomized)\n",
    "    grouped_rhf_randomized[name] = rhf_randomized\n",
    "    \n",
    "    # control\n",
    "    rhf_control = []\n",
    "    for n in range(len(pipes[0].rhf_control)):\n",
    "        rhf_control_ = [pipes[i].rhf_control[n] for i in group.index]\n",
    "        rhf_control_ = RipleysAnalysis_concat(cls=lc.RipleysHFunction, datasets=rhf_control_)\n",
    "        rhf_control_ = RipleyAnalysis_statistics(rhf_control_)\n",
    "        rhf_control.append(rhf_control_.statistics['mean'])\n",
    "    \n",
    "    rhf_control = RipleysAnalysis_concat(cls=lc.RipleysHFunction, datasets=rhf_control)\n",
    "    rhf_control = RipleyAnalysis_statistics(rhf_control)\n",
    "    grouped_rhf_control[name] = rhf_control"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for group, (name, grouped_rhf) in zip(grouped.groups, grouped_rhf_estimates.items()):\n",
    "    grouped_rhf.statistics.to_csv(name + '_estimates.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for group, (name, grouped_rhf) in zip(grouped.groups, grouped_rhf_randomized.items()):\n",
    "    grouped_rhf.statistics.to_csv(name + '_randomized.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for group, (name, grouped_rhf) in zip(grouped.groups, grouped_rhf_control.items()):\n",
    "    grouped_rhf.statistics.to_csv(name + '_control.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,8))\n",
    "for group, (name, grouped_rhf) in zip(grouped.groups, grouped_rhf_estimates.items()):\n",
    "    ax.plot('mean', data=grouped_rhf.statistics, label=group + \"-estimates\")\n",
    "    ax.fill_between(grouped_rhf.statistics.index,'CI_lower', 'CI_upper', data=grouped_rhf.statistics, color='lightgrey')\n",
    "\n",
    "for group, (name, grouped_rhf) in zip(grouped.groups, grouped_rhf_randomized.items()):\n",
    "    ax.plot('mean', data=grouped_rhf.statistics, label=group+\"-randomized\")\n",
    "    ax.fill_between(grouped_rhf.statistics.index, 'CI_lower', 'CI_upper', data=grouped_rhf.statistics, color='lightgrey')\n",
    "\n",
    "for group, (name, grouped_rhf) in zip(grouped.groups, grouped_rhf_control.items()):\n",
    "    ax.plot('mean', data=grouped_rhf.statistics, label=group+\"-control\")\n",
    "    ax.fill_between(grouped_rhf.statistics.index, 'CI_lower', 'CI_upper', data=grouped_rhf.statistics, color='lightgrey')\n",
    "\n",
    "ax.set(title='All Data',\n",
    "       xlabel='distance (nm)',\n",
    "       ylabel=\"Ripley's h function\") \n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,8))\n",
    "\n",
    "for group, (name, grouped_rhf) in zip(grouped.groups, grouped_rhf_estimates.items()):\n",
    "    ax.plot('mean', data=grouped_rhf.statistics, label=group + \"-estimates\")\n",
    "    ax.fill_between(grouped_rhf.statistics.index,'CI_lower', 'CI_upper', data=grouped_rhf.statistics, color='lightgrey')\n",
    "\n",
    "ax.set(title='Experimental Data',\n",
    "       xlabel='distance (nm)',\n",
    "       ylabel=\"Ripley's h function\") \n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### randomized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,8))\n",
    "\n",
    "for group, (name, grouped_rhf) in zip(grouped.groups, grouped_rhf_randomized.items()):\n",
    "    ax.plot('mean', data=grouped_rhf.statistics, label=group+\"-randomized\")\n",
    "    ax.fill_between(grouped_rhf.statistics.index, 'CI_lower', 'CI_upper', data=grouped_rhf.statistics, color='lightgrey')\n",
    "\n",
    "ax.set(title='Randomized Data',\n",
    "       xlabel='distance (nm)',\n",
    "       ylabel=\"Ripley's h function\") \n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,8))\n",
    "\n",
    "for group, (name, grouped_rhf) in zip(grouped.groups, grouped_rhf_control.items()):\n",
    "    ax.plot('mean', data=grouped_rhf.statistics, label=group+\"-control\")\n",
    "    ax.fill_between(grouped_rhf.statistics.index, 'CI_lower', 'CI_upper', data=grouped_rhf.statistics, color='lightgrey')\n",
    "\n",
    "ax.set(title='Control Data',\n",
    "       xlabel='distance (nm)',\n",
    "       ylabel=\"Ripley's h function\") \n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in list(grouped.groups):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,8))\n",
    "    data_selectors = (grouped_rhf_estimates, grouped_rhf_randomized, grouped_rhf_control)\n",
    "    label_extensions = (\"-estimates\", \"-randomized\", \"-control\")\n",
    "\n",
    "    colors = mcolors.TABLEAU_COLORS\n",
    "    for label_extension, grouped_rhf, color in zip(label_extensions, data_selectors, colors):\n",
    "        ax.plot('mean', data=grouped_rhf[group].statistics, c=color, linewidth=4, label=group+label_extension)\n",
    "        ax.plot('CI_lower', data=grouped_rhf[group].statistics, c=color, linestyle=\"dashed\")\n",
    "        ax.plot('CI_upper', data=grouped_rhf[group].statistics, c=color, linestyle=\"dashed\")\n",
    "        ax.fill_between(grouped_rhf[group].statistics.index, 'CI_lower', 'CI_upper', data=grouped_rhf[group].statistics, color='lightgrey')\n",
    "\n",
    "    ax.set(title=group,\n",
    "       xlabel='distance (nm)',\n",
    "       ylabel=\"Ripley's h function\") \n",
    "    plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publication figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(7.2, 5.8))\n",
    "\n",
    "group = \"sparse\"\n",
    "\n",
    "data_selectors = (grouped_rhf_randomized, grouped_rhf_control, grouped_rhf_estimates)\n",
    "# labels = (label_definitions[group], \" \", \" \")\n",
    "labels = (\" \", \" \", group)\n",
    "colors = ['darkgray', 'darkgray', '#a6cee3']\n",
    "\n",
    "for label, grouped_rhf, color in zip(labels, data_selectors, colors):\n",
    "    if grouped_rhf is not grouped_rhf_estimates:\n",
    "        ax.plot('CI_lower', data=grouped_rhf[group].statistics, c='grey', linestyle=\"dashed\", label='')\n",
    "        ax.plot('CI_upper', data=grouped_rhf[group].statistics, c='grey', linestyle=\"dashed\", label='')\n",
    "        ax.fill_between(grouped_rhf[group].statistics.index, 'CI_lower', 'CI_upper', data=grouped_rhf[group].statistics, color='lightgrey')\n",
    "    ax.plot('mean', data=grouped_rhf[group].statistics, c=color, linewidth=4, label=label)\n",
    "\n",
    "ax.set_xlabel('Distance (nm)', fontsize=28)\n",
    "ax.set_ylabel(\"Ripley's h function\", fontsize=28)\n",
    "plt.xticks(fontsize=22)\n",
    "plt.yticks(fontsize=22)\n",
    "\n",
    "plt.text(0.4, 0.9, labels[2], fontsize=24, transform=ax.transAxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig.savefig('../figures/Ripley_myc_sparse.pdf', dpi=1200, bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(7.2, 5.8))\n",
    "\n",
    "group = \"dense\"\n",
    "\n",
    "data_selectors = (grouped_rhf_randomized, grouped_rhf_control, grouped_rhf_estimates)\n",
    "# labels = (label_definitions[group], \" \", \" \")\n",
    "labels = (\" \", \" \", group)\n",
    "colors = ['darkgray', 'darkgray', '#1f78b4']\n",
    "\n",
    "for label, grouped_rhf, color in zip(labels, data_selectors, colors):\n",
    "    if grouped_rhf is not grouped_rhf_estimates:\n",
    "        ax.plot('CI_lower', data=grouped_rhf[group].statistics, c='grey', linestyle=\"dashed\", label='')\n",
    "        ax.plot('CI_upper', data=grouped_rhf[group].statistics, c='grey', linestyle=\"dashed\", label='')\n",
    "        ax.fill_between(grouped_rhf[group].statistics.index, 'CI_lower', 'CI_upper', data=grouped_rhf[group].statistics, color='lightgrey')\n",
    "    ax.plot('mean', data=grouped_rhf[group].statistics, c=color, linewidth=4, label=label)\n",
    "\n",
    "ax.set_xlabel('Distance (nm)', fontsize=28)\n",
    "ax.set_ylabel(\"Ripley's h function\", fontsize=28)\n",
    "plt.xticks(fontsize=22)\n",
    "plt.yticks(fontsize=22)\n",
    "\n",
    "plt.text(0.4, 0.9, labels[2], fontsize=24, transform=ax.transAxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig.savefig('../figures/Ripley_myc_dense.pdf', dpi=1200, bbox_inches='tight') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
